{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': \"\\nProvide a requirement analysis for building an AI-powered career counseling assistant that uses Prompt Templates. The assistant should have reusable templates that can be dynamically filled with user-specific information. For example:\\n\\nTemplate: 'For a USER with SKILLSET, here’s a suggested career path and key actions to take:'\\nThe assistant will fill in the user’s details and generate a personalized career recommendation, including potential job roles, growth opportunities, and necessary steps to achieve the user’s goals.\\n\", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "Building a Career Recommendation Assistant\n",
      "=============================================\n",
      "\n",
      "**Overview**\n",
      "\n",
      "This project aims to create an intelligent career guidance system that suggests personalized career paths for users based on their skills, interests, and values. The system will utilize natural language processing (NLP) techniques to analyze user input and provide relevant recommendations.\n",
      "\n",
      "**System Components**\n",
      "\n",
      "1. **Data Collection**\n",
      "\t* User Input: Survey or questionnaire to gather information about the user's skills, interests, work experience, and education.\n",
      "\t* Job Titles:\n",
      "Time taken: 31.649s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "TEMPLATE_BEFORE = f\"\"\"\n",
    "Provide a requirement analysis for building an AI-powered career counseling assistant that uses Prompt Templates. The assistant should have reusable templates that can be dynamically filled with user-specific information. For example:\n",
    "\n",
    "Template: 'For a USER with SKILLSET, here’s a suggested career path and key actions to take:'\n",
    "The assistant will fill in the user’s details and generate a personalized career recommendation, including potential job roles, growth opportunities, and necessary steps to achieve the user’s goals.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = TEMPLATE_BEFORE \n",
    "\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
