{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deep Comparison Prompting**  \n",
    "\n",
    "Deep Comparison Prompting is a technique where the AI model is asked to compare multiple entities, ideas, or concepts in depth to assist the user in making informed decisions. This method is ideal for analyzing similarities, differences, advantages, and disadvantages between various options, making it particularly useful for career decision-making, product comparison, and strategic planning.  \n",
    "\n",
    "## **Automatic Deep Comparison Prompting (Auto-DCP)**  \n",
    "\n",
    "Manually designing prompts for deep comparisons can be time-consuming and complex. **Auto-DCP** automates the process by dynamically generating comparison structures based on user queries. It helps the model evaluate and contrast multiple options with detailed, well-structured comparisons that enhance clarity and decision-making accuracy.  \n",
    "\n",
    "Auto-DCP operates in three main stages:  \n",
    "\n",
    "1. **Identifying Key Comparison Factors:** The system automatically extracts the relevant attributes or criteria from the user query for comparison (e.g., job requirements, skills, salaries, benefits).  \n",
    "2. **Generating Comparative Responses:** The model generates in-depth comparisons based on the extracted factors, offering a balanced evaluation of each option.  \n",
    "3. **Ranking and Presenting Options:** The system ranks the options or presents them in a way that helps the user understand the trade-offs, advantages, and disadvantages clearly.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying: Chain of Thought (COT)...\n",
      "{'model': 'llama3.2:latest', 'prompt': \"\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Chain of Thought (COT).\\n        The assistant should break down user queries step-by-step, reasoning through the individual components of career decision-making. \\n        For example, if a user asks for career advice, the assistant should first analyze the user's interests, strengths, and goals, \\n        then reason through skills, job market trends, salary expectations, and long-term growth prospects, ultimately providing a personalized plan.\\n        The assistant's logic should be clear, providing step-by-step explanations for every recommendation.\\n    \", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "Here is a requirement analysis for building an AI-powered...\n",
      "Time taken: 20.376s\n",
      "--------------------------------------------------\n",
      "Querying: Tree of Thoughts (TOT)...\n",
      "{'model': 'llama3.2:latest', 'prompt': \"\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Tree of Thoughts (TOT).\\n        The assistant should take the user's inputs (skills, interests, career goals) and generate multiple pathways, each corresponding to different \\n        career options, educational choices, or job roles. Each pathway should branch out into further options, and the assistant should evaluate \\n        the pros and cons of each branch, helping the user choose the best path based on their preferences.\\n    \", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "Here's a requirement analysis for building an AI-powered...\n",
      "Time taken: 14.248s\n",
      "--------------------------------------------------\n",
      "Querying: Contrastive Prompting...\n",
      "{'model': 'llama3.2:latest', 'prompt': '\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Contrastive Prompting.\\n        The assistant should compare two or more career paths, job roles, or educational choices and contrast their merits. For example, when asked \\n        about the difference between two career options, such as Data Science and Software Engineering, the assistant should provide a detailed \\n        comparison based on factors such as job market demand, required skills, salary trends, and long-term career growth.\\n    ', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "Here is a requirement analysis for building an AI-powered...\n",
      "Time taken: 14.285s\n",
      "--------------------------------------------------\n",
      "Querying: Few-Shot Prompting...\n",
      "{'model': 'llama3.2:latest', 'prompt': \"\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Few-Shot Prompting.\\n        The assistant should be trained with a few example queries and responses to provide accurate career advice.\\n        For example:\\n        - User: 'What career options are available for someone skilled in machine learning?'\\n        - Bot: 'You could explore roles like Data Scientist, AI Engineer, or Machine Learning Specialist.'\\n    \", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "Here's a comprehensive requirement analysis for building an AI...\n",
      "Time taken: 13.167s\n",
      "--------------------------------------------------\n",
      "Querying: General Knowledge Prompting...\n",
      "{'model': 'llama3.2:latest', 'prompt': '\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses General Knowledge Prompting.\\n        The assistant should draw on a broad knowledge base of job market trends, career options, and professional skills to answer user queries.\\n        For example, when asked about the benefits of pursuing a career in cybersecurity, the assistant should explain the demand for cybersecurity professionals, \\n        required skills, job roles, and salary ranges.\\n    ', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "**Requirement Analysis: AI-Powered Career Counseling Assistant...\n",
      "Time taken: 12.825s\n",
      "--------------------------------------------------\n",
      "Querying: Meta Prompting...\n",
      "{'model': 'llama3.2:latest', 'prompt': \"\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Meta Prompting.\\n        The assistant should first analyze the user's query and generate relevant background information or context before providing career recommendations or advice.\\n    \", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "**Requirement Analysis: AI-Powered Career Counseling Assistant...\n",
      "Time taken: 8.077s\n",
      "--------------------------------------------------\n",
      "Querying: Prompt Chaining...\n",
      "{'model': 'llama3.2:latest', 'prompt': \"\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Prompt Chaining.\\n        The assistant should use a series of interrelated prompts to guide the user through the career decision-making process. \\n        For example:\\n\\n        User asks: 'What career should I pursue in tech?'\\n        - *Step 1:* Assistant prompts the user for their interests, skills, and goals.\\n        - *Step 2:* Based on the user's inputs, the assistant suggests a list of career paths.\\n        - *Step 3:* The user asks about salary expectations for a certain career path.\\n        - *Step 4:* The assistant provides detailed information about average salaries in the field.\\n        - *Step 5:* If the user asks about required skills, the assistant suggests relevant courses and certifications.\\n\\n        The assistant ensures that *each prompt builds on the previous one*, creating a seamless user experience.\\n    \", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "Here's a more detailed outline of how this AI...\n",
      "Time taken: 29.064s\n",
      "--------------------------------------------------\n",
      "Querying: Prompt Template...\n",
      "{'model': 'llama3.2:latest', 'prompt': \"\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Prompt Templates.\\n        The assistant should have reusable templates that can be dynamically filled with user-specific information.\\n        For example:\\n        - Template: 'For a USER with SKILLSET, here’s a suggested career path and key actions to take:'\\n    \", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "Here's a comprehensive requirement analysis for building an AI...\n",
      "Time taken: 14.64s\n",
      "--------------------------------------------------\n",
      "Querying: Self-Consistency...\n",
      "{'model': 'llama3.2:latest', 'prompt': \"\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Self-Consistency.\\n        The assistant should generate multiple responses for the same query and assess which answer is the most consistent. \\n        It should weigh the responses based on factors such as accuracy, relevance to the user's goals, and alignment with current job market trends.\\n    \", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "Requirement Analysis: AI-Powered Career Counseling Assistant using...\n",
      "Time taken: 13.798s\n",
      "--------------------------------------------------\n",
      "Querying: Zero-Shot Prompting...\n",
      "{'model': 'llama3.2:latest', 'prompt': \"\\n        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Zero-Shot Prompting.\\n        The assistant should be able to respond accurately to queries without requiring specific training examples.\\n        For example, if a user asks: 'What are the best career options in the field of Artificial Intelligence?'\\n        The assistant should provide an accurate response based on general knowledge and trends without needing prior examples.\\n    \", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 10}}\n",
      "Response:\n",
      "Here's a requirement analysis for building an AI-powered...\n",
      "Time taken: 10.688s\n",
      "--------------------------------------------------\n",
      "\n",
      "Best Prompt Based on Evaluation:\n",
      "Prompt: Meta Prompting\n",
      "Response: **Requirement Analysis: AI-Powered Career Counseling Assistant...\n",
      "Time taken: 8.077s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "prompts = {\n",
    "    \"Chain of Thought (COT)\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Chain of Thought (COT).\n",
    "        The assistant should break down user queries step-by-step, reasoning through the individual components of career decision-making. \n",
    "        For example, if a user asks for career advice, the assistant should first analyze the user's interests, strengths, and goals, \n",
    "        then reason through skills, job market trends, salary expectations, and long-term growth prospects, ultimately providing a personalized plan.\n",
    "        The assistant's logic should be clear, providing step-by-step explanations for every recommendation.\n",
    "    \"\"\",\n",
    "\n",
    "    \"Tree of Thoughts (TOT)\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Tree of Thoughts (TOT).\n",
    "        The assistant should take the user's inputs (skills, interests, career goals) and generate multiple pathways, each corresponding to different \n",
    "        career options, educational choices, or job roles. Each pathway should branch out into further options, and the assistant should evaluate \n",
    "        the pros and cons of each branch, helping the user choose the best path based on their preferences.\n",
    "    \"\"\",\n",
    "\n",
    "    \"Contrastive Prompting\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Contrastive Prompting.\n",
    "        The assistant should compare two or more career paths, job roles, or educational choices and contrast their merits. For example, when asked \n",
    "        about the difference between two career options, such as Data Science and Software Engineering, the assistant should provide a detailed \n",
    "        comparison based on factors such as job market demand, required skills, salary trends, and long-term career growth.\n",
    "    \"\"\",\n",
    "\n",
    "    \"Few-Shot Prompting\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Few-Shot Prompting.\n",
    "        The assistant should be trained with a few example queries and responses to provide accurate career advice.\n",
    "        For example:\n",
    "        - User: 'What career options are available for someone skilled in machine learning?'\n",
    "        - Bot: 'You could explore roles like Data Scientist, AI Engineer, or Machine Learning Specialist.'\n",
    "    \"\"\",\n",
    "\n",
    "    \"General Knowledge Prompting\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses General Knowledge Prompting.\n",
    "        The assistant should draw on a broad knowledge base of job market trends, career options, and professional skills to answer user queries.\n",
    "        For example, when asked about the benefits of pursuing a career in cybersecurity, the assistant should explain the demand for cybersecurity professionals, \n",
    "        required skills, job roles, and salary ranges.\n",
    "    \"\"\",\n",
    "\n",
    "    \"Meta Prompting\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Meta Prompting.\n",
    "        The assistant should first analyze the user's query and generate relevant background information or context before providing career recommendations or advice.\n",
    "    \"\"\",\n",
    "\n",
    "    \"Prompt Chaining\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Prompt Chaining.\n",
    "        The assistant should use a series of interrelated prompts to guide the user through the career decision-making process. \n",
    "        For example:\n",
    "\n",
    "        User asks: 'What career should I pursue in tech?'\n",
    "        - *Step 1:* Assistant prompts the user for their interests, skills, and goals.\n",
    "        - *Step 2:* Based on the user's inputs, the assistant suggests a list of career paths.\n",
    "        - *Step 3:* The user asks about salary expectations for a certain career path.\n",
    "        - *Step 4:* The assistant provides detailed information about average salaries in the field.\n",
    "        - *Step 5:* If the user asks about required skills, the assistant suggests relevant courses and certifications.\n",
    "\n",
    "        The assistant ensures that *each prompt builds on the previous one*, creating a seamless user experience.\n",
    "    \"\"\",\n",
    "\n",
    "    \"Prompt Template\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Prompt Templates.\n",
    "        The assistant should have reusable templates that can be dynamically filled with user-specific information.\n",
    "        For example:\n",
    "        - Template: 'For a USER with SKILLSET, here’s a suggested career path and key actions to take:'\n",
    "    \"\"\",\n",
    "\n",
    "    \"Self-Consistency\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Self-Consistency.\n",
    "        The assistant should generate multiple responses for the same query and assess which answer is the most consistent. \n",
    "        It should weigh the responses based on factors such as accuracy, relevance to the user's goals, and alignment with current job market trends.\n",
    "    \"\"\",\n",
    "\n",
    "    \"Zero-Shot Prompting\": \"\"\"\n",
    "        Provide a requirement analysis for building an AI-powered career counseling assistant that uses Zero-Shot Prompting.\n",
    "        The assistant should be able to respond accurately to queries without requiring specific training examples.\n",
    "        For example, if a user asks: 'What are the best career options in the field of Artificial Intelligence?'\n",
    "        The assistant should provide an accurate response based on general knowledge and trends without needing prior examples.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "model_name = \"llama3.2:latest\"\n",
    "temperature = 1.0\n",
    "num_ctx = 200\n",
    "num_predict = 10\n",
    "\n",
    "def query_model(prompt):\n",
    "    payload = create_payload(target=\"ollama\", model=model_name, prompt=prompt, temperature=temperature, num_ctx=num_ctx, num_predict=num_predict)\n",
    "    time, response = model_req(payload=payload)\n",
    "    return response, time\n",
    "\n",
    "results = {}\n",
    "for prompt_name, prompt_text in prompts.items():\n",
    "    print(f\"Querying: {prompt_name}...\")\n",
    "    response, time_taken = query_model(prompt_text)\n",
    "    \n",
    "    results[prompt_name] = {\n",
    "        \"response\": response,\n",
    "        \"time_taken\": time_taken\n",
    "    }\n",
    "    \n",
    "    print(f\"Response:\\n{response[:150]}...\\nTime taken: {time_taken}s\\n{'-'*50}\")\n",
    "\n",
    "def evaluate_best_prompt(results):\n",
    "    best_prompt = None\n",
    "    best_score = float('inf')  \n",
    "\n",
    "    for technique, data in results.items():\n",
    "        response, time_taken = data['response'], data['time_taken']\n",
    "        \n",
    "       \n",
    "        score = time_taken \n",
    "        \n",
    "        if \"comprehensive\" in response.lower() or \"detailed\" in response.lower():\n",
    "            score -= 5  \n",
    "        if \"example implementation\" in response.lower():\n",
    "            score -= 3 \n",
    "        if \"analysis\" in response.lower():\n",
    "            score -= 2  \n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_prompt = technique\n",
    "\n",
    "    return best_prompt\n",
    "\n",
    "best_prompt_technique = evaluate_best_prompt(results)\n",
    "\n",
    "print(\"\\nBest Prompt Based on Evaluation:\")\n",
    "print(f\"Prompt: {best_prompt_technique}\")\n",
    "print(f\"Response: {results[best_prompt_technique]['response'][:150]}...\")  \n",
    "print(f\"Time taken: {results[best_prompt_technique]['time_taken']}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
