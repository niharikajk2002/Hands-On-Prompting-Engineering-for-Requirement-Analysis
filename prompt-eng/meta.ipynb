{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique in prompt engineering that emphasizes the structural and syntactical organization of tasks and problems rather than focusing on their specific content. The objective is to create a more abstract, form-driven way of engaging with large language models (LLMs), highlighting patterns and structure over traditional content-focused methods.\n",
    "\n",
    "As outlined by [Zhang et al. (2024)](https://arxiv.org/abs/2311.11482), the defining features of meta prompting include:\n",
    "\n",
    "* Structure-Oriented: Prioritizes the organization and pattern of problems and solutions instead of specific content.\n",
    "* Syntax-Guided: Leverages syntax as a template to shape the expected responses or solutions.\n",
    "* Abstract Frameworks: Uses abstract examples as blueprints, demonstrating the structure of tasks without relying on concrete details.\n",
    "* Domain Versatility: Can be applied across multiple fields, offering structured solutions to diverse problem types.\n",
    "* Categorical Approach: Draws on type theory to organize and categorize components logically, enhancing prompt coherence and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fmeta.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': \"\\nProvide a requirement analysis for building an AI-powered career counseling assistant that uses Meta Prompting. The assistant should first analyze the user's query and generate relevant background information or context before providing career recommendations or advice. For example:\\n\\nUser asks: 'What skills should I focus on to transition into a data science career?'\\nThe assistant first analyzes the query and identifies that the user is looking to transition into a new field. It then responds: 'To transition into data science, you should focus on learning programming languages like Python or R, gaining expertise in machine learning algorithms, and developing a strong understanding of statistics. It's also important to familiarize yourself with data visualization tools like Tableau and Power BI, and learn about databases and data cleaning techniques.'\\n\\nUser asks: 'How can I move into a cybersecurity role?'\\nThe assistant analyzes the question, recognizing the user's interest in cybersecurity, and responds: 'To move into a cybersecurity role, you should focus on learning key skills such as network security, ethical hacking, and threat analysis. Certifications like CompTIA Security+, CISSP, and CEH are highly valued in the industry, along with a solid understanding of encryption techniques and risk management.'\\n\\nThe assistant should assess the user's question to provide personalized career advice based on their interests and goals.\\n\", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 90, 'num_predict': 50}}\n",
      "It seems like you're considering a career change or exploring options related to technology. The statement provides a general overview of skills and knowledge that are valuable in the industry, but doesn't directly address your specific situation.\n",
      "\n",
      "To better understand your needs, I have\n",
      "Time taken: 21.342s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## META PROMPTING - NUTRITION & FITNESS BOT\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "\n",
    "\n",
    "#### (2) Apply the Meta Prompting Technique  \n",
    "META_PROMPT = f\"\"\"\n",
    "Provide a requirement analysis for building an AI-powered career counseling assistant that uses Meta Prompting. The assistant should first analyze the user's query and generate relevant background information or context before providing career recommendations or advice. For example:\n",
    "\n",
    "User asks: 'What skills should I focus on to transition into a data science career?'\n",
    "The assistant first analyzes the query and identifies that the user is looking to transition into a new field. It then responds: 'To transition into data science, you should focus on learning programming languages like Python or R, gaining expertise in machine learning algorithms, and developing a strong understanding of statistics. It's also important to familiarize yourself with data visualization tools like Tableau and Power BI, and learn about databases and data cleaning techniques.'\n",
    "\n",
    "User asks: 'How can I move into a cybersecurity role?'\n",
    "The assistant analyzes the question, recognizing the user's interest in cybersecurity, and responds: 'To move into a cybersecurity role, you should focus on learning key skills such as network security, ethical hacking, and threat analysis. Certifications like CompTIA Security+, CISSP, and CEH are highly valued in the industry, along with a solid understanding of encryption techniques and risk management.'\n",
    "\n",
    "The assistant should assess the user's question to provide personalized career advice based on their interests and goals.\n",
    "\"\"\"\n",
    "\n",
    "#### (3) Configure the Model Request, Simulating Workflow Orchestration  \n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=META_PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=90, \n",
    "                         num_predict=50)\n",
    "\n",
    "### YOU DON'T NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
